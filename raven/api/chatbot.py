import frappe
from frappe import _
from frappe.model.document import Document
from raven.ai.openai_client import get_open_ai_client
from raven.chatbot.doctype.chatconversation.chatconversation import ChatConversation
from raven.chatbot.doctype.chatmessage.chatmessage import ChatMessage
import uuid
import traceback
import os
import time
from frappe.utils import get_files_path
from PyPDF2 import PdfReader
import docx
import pandas as pd
import tiktoken

# Helper: T·∫°o tin nh·∫Øn
def create_message(conversation_id, message, is_user=True, message_type="Text", file=None):
    message_id = str(uuid.uuid4())
    chat_message = frappe.get_doc({
        "doctype": "ChatMessage",
        "name": message_id,
        "parent": conversation_id,
        "parentfield": "messages",
        "parenttype": "ChatConversation",
        "sender": frappe.session.user if is_user else "AI Assistant",
        "is_user": is_user,
        "message": message,
        "message_type": message_type,
        "file": file,
        "timestamp": frappe.utils.now()
    })
    chat_message.insert()
    return chat_message

def extract_text_from_file(file_url):
    is_private = file_url.startswith("/private/")
    base_path = get_files_path(is_private=is_private)
    full_path = os.path.join(base_path, os.path.basename(file_url))

    try:
        if file_url.endswith(".pdf"):
            with open(full_path, 'rb') as f:
                reader = PdfReader(f)
                return '\n'.join([page.extract_text() for page in reader.pages if page.extract_text()])
        elif file_url.endswith(".docx"):
            doc = docx.Document(full_path)
            return '\n'.join([p.text for p in doc.paragraphs])
        elif file_url.endswith((".xls", ".xlsx")):
            df = pd.read_excel(full_path)
            return df.to_string(index=False)
        elif file_url.endswith(".txt"):
            with open(full_path, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        return f"[Kh√¥ng th·ªÉ ƒë·ªçc file: {e}]"

    return "[ƒê·ªãnh d·∫°ng file kh√¥ng h·ªó tr·ª£]"

# Helper: X√¢y d·ª±ng context t·ª´ c√°c tin nh·∫Øn g·∫ßn nh·∫•t
def build_context(conversation_id, model="gpt-4o"):
    # C·∫•u h√¨nh tokens ƒë·ªÉ h·ªó tr·ª£ 5 files (5MB m·ªói file) + text 11,000 t·ª´
    MAX_TOTAL_TOKENS = 80000      # T·ªïng tokens cho input (trong gi·ªõi h·∫°n 128K c·ªßa GPT-4o)
    MAX_FILE_TOKENS = 10000       # M·ªói file t·ªëi ƒëa 10K tokens (‚âà 5MB content)
    MAX_MESSAGE_COUNT = 100       # TƒÉng s·ªë message ƒë·ªÉ l∆∞u ƒë·ªß history v·ªõi files

    try:
        encoding = tiktoken.encoding_for_model(model)
    except:
        encoding = tiktoken.get_encoding("cl100k_base")

    def token_len(text):
        return len(encoding.encode(text or ""))

    frappe.db.commit()

    messages = frappe.get_all(
        "ChatMessage",
        filters={"parent": conversation_id},
        fields=["sender", "is_user", "message", "timestamp", "file", "message_type"],
        order_by="timestamp desc",
        limit_page_length=MAX_MESSAGE_COUNT
    )[::-1]

    # Th√™m system message ƒë·ªÉ ghi ƒë√® th√¥ng tin m·∫∑c ƒë·ªãnh
    system_message = {
        "role": "system",
        "content": """B·∫°n l√† tr·ª£ l√Ω AI ti√™n ti·∫øn ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi m√¥ h√¨nh GPT-4o c·ªßa OpenAI. 

H∆∞·ªõng d·∫´n tr·∫£ l·ªùi:
- H√£y tr·∫£ l·ªùi m·ªôt c√°ch ch√≠nh x√°c, chi ti·∫øt v√† th√¥ng minh
- S·ª≠ d·ª•ng ti·∫øng Vi·ªát t·ª± nhi√™n v√† th√¢n thi·ªán
- Khi ƒë∆∞·ª£c h·ªèi v·ªÅ ki·∫øn th·ª©c chuy√™n m√¥n, h√£y ƒëi s√¢u v√†o chi ti·∫øt
- N·∫øu c·∫ßn gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ ph·ª©c t·∫°p, h√£y ph√¢n t√≠ch t·ª´ng b∆∞·ªõc
- Khi kh√¥ng ch·∫Øc ch·∫Øn, h√£y th·ª´a nh·∫≠n v√† ƒë∆∞a ra c√°c kh·∫£ nƒÉng
- Lu√¥n c·ªë g·∫Øng cung c·∫•p gi√° tr·ªã th·ª±c s·ª± trong m·ªói c√¢u tr·∫£ l·ªùi"""
    }
    
    context = [system_message]
    total_tokens = token_len(system_message["content"])

    for msg in messages:
        content = msg.message or ""

        # N·∫øu c√≥ file ‚Üí tr√≠ch n·ªôi dung
        if msg.file:
            file_text = extract_text_from_file(msg.file) or ""
            file_tokens = token_len(file_text)

            if file_tokens == 0:
                continue
            elif file_tokens > MAX_FILE_TOKENS:
                # R√∫t g·ªçn file qu√° l·ªõn nh∆∞ng gi·ªØ nhi·ªÅu n·ªôi dung h∆°n (cho files 5MB)
                approx_summary = file_text.strip()[:7500]  # TƒÉng t·ª´ 1500 l√™n 7500 chars
                content += (
                    "\n\n[N·ªôi dung file t√≥m t·∫Øt:]\n"
                    + approx_summary +
                    "\n\n[Ghi ch√∫: N·ªôi dung ƒë√£ ƒë∆∞·ª£c r√∫t g·ªçn v√¨ qu√° d√†i]"
                )
            else:
                content += f"\n\n[N·ªôi dung file ƒë√≠nh k√®m:]\n{file_text.strip()}"

        msg_tokens = token_len(content)

        if total_tokens + msg_tokens > MAX_TOTAL_TOKENS:
            continue

        total_tokens += msg_tokens
        context.append({
            "role": "user" if msg.is_user else "assistant",
            "content": content.strip()
        })

    frappe.log_error(
        f"[BUILD_CONTEXT] conversation_id={conversation_id}, messages={len(messages)}, context={len(context)}, tokens={total_tokens}",
        "Build Context - Token Accurate"
    )

    return context

# Helper: G·ªçi OpenAI
def call_openai(context):
    raven_settings = frappe.get_cached_doc("Raven Settings")
    if not raven_settings.enable_ai_integration:
        return "AI ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t. Vui l√≤ng li√™n h·ªá admin."

    client = get_open_ai_client()
    if not client:
        return "Kh√¥ng th·ªÉ k·∫øt n·ªëi OpenAI. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh API key."

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=context,
        temperature=0.3,  # Gi·∫£m temperature ƒë·ªÉ c√≥ response ·ªïn ƒë·ªãnh v√† ch√≠nh x√°c h∆°n
        max_tokens=8000,  # TƒÉng max_tokens ƒë·ªÉ c√≥ response ƒë·∫ßy ƒë·ªß cho c√°c files l·ªõn
        top_p=0.9,        # Th√™m top_p ƒë·ªÉ ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng response
        frequency_penalty=0.1  # Gi·∫£m l·∫∑p l·∫°i
    )
    return response.choices[0].message.content


@frappe.whitelist()
def get_conversations():
    return frappe.get_all(
        "ChatConversation",
        filters={"user": frappe.session.user},
        fields=["name", "title", "creation"],
        order_by="creation desc"
    )


@frappe.whitelist()
def create_conversation(title):
    conversation = frappe.get_doc({
        "doctype": "ChatConversation",
        "title": title,
        "user": frappe.session.user
    })
    conversation.insert()
    return conversation


@frappe.whitelist()
def get_messages(conversation_id=None):
    if not conversation_id:
        return []

    return frappe.get_all(
        "ChatMessage",
        filters={"parent": conversation_id},
        fields=["name", "sender", "is_user", "message", "timestamp" ,"message_type" ,"file"],
        order_by="timestamp asc"
    )


@frappe.whitelist()
def send_message(conversation_id, message, is_user=True, message_type="Text", file=None, trigger_ai=True):
    try:
        if not frappe.db.exists("ChatConversation", conversation_id):
            frappe.throw(_("Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i"))

        chat_message = create_message(conversation_id, message, is_user, message_type, file)

        # Commit message tr∆∞·ªõc khi enqueue AI reply
        frappe.db.commit()

        # Ch·ªâ trigger AI reply n·∫øu trigger_ai = True v√† l√† user message
        if is_user and trigger_ai:
            # Delay nh·ªè ƒë·ªÉ ƒë·∫£m b·∫£o message ƒë√£ ƒë∆∞·ª£c commit
            frappe.enqueue(
                "raven.api.chatbot.handle_ai_reply",
                conversation_id=conversation_id,
                now=False,
                timeout=600  # 10 ph√∫t timeout cho files l·ªõn
            )

        return chat_message.name

    except Exception as e:
        frappe.log_error(
            f"{str(e)}\n{traceback.format_exc()}",
            "G·ª≠i tin nh·∫Øn th·∫•t b·∫°i"
        )
        frappe.throw(_("C√≥ l·ªói x·∫£y ra khi g·ª≠i tin nh·∫Øn"))


@frappe.whitelist()
def trigger_ai_reply(conversation_id, message_text=None):
    """
    API ƒë·ªÉ trigger AI reply cho conversation sau khi upload files
    """
    try:
        if not frappe.db.exists("ChatConversation", conversation_id):
            frappe.throw(_("Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i"))
        
        # T·∫°o message t·ª´ user n·∫øu c√≥ message_text
        if message_text:
            create_message(conversation_id, message_text, is_user=True, message_type="Text")
            frappe.db.commit()
        
        # Enqueue AI reply
        frappe.enqueue(
            "raven.api.chatbot.handle_ai_reply",
            conversation_id=conversation_id,
            now=False,
            timeout=600  # 10 ph√∫t timeout cho files l·ªõn
        )
        
        return {"success": True, "message": "AI reply ƒë√£ ƒë∆∞·ª£c trigger"}
        
    except Exception as e:
        frappe.log_error(
            f"{str(e)}\n{traceback.format_exc()}",
            "Trigger AI Reply Error"
        )
        frappe.throw(_("C√≥ l·ªói x·∫£y ra khi g·ªçi AI reply"))


def handle_ai_reply(conversation_id):
    # T·∫°o lock key ƒë·ªÉ tr√°nh duplicate processing
    lock_key = f"ai_reply_lock_{conversation_id}"
    
    try:
        # Ki·ªÉm tra xem c√≥ process n√†o ƒëang x·ª≠ l√Ω conversation n√†y kh√¥ng
        if frappe.cache().get(lock_key):
            frappe.logger().info(f"[AI SKIPPED] Another AI reply process is already running for conversation {conversation_id}")
            return
        
        # Set lock v·ªõi timeout 60 gi√¢y
        frappe.cache().setex(lock_key, 60, "processing")
        
        max_retries = 5
        delay_base = 1
        context = []

        for attempt in range(max_retries):
            if attempt > 0:
                time.sleep(delay_base * attempt)

            # üõ†Ô∏è Fix race condition: delay nh·ªè ·ªü l·∫ßn ƒë·∫ßu ƒë·ªÉ ch·ªù file ƒë∆∞·ª£c commit
            if attempt == 0:
                time.sleep(0.3)

            context = build_context(conversation_id)

            if context:
                break

            frappe.log_error(
                f"[AI RETRY] Attempt {attempt + 1}/{max_retries} - context r·ªóng",
                "AI Handler - Retry Context"
            )

        if not context:
            frappe.log_error(
                f"[AI SKIPPED] Context v·∫´n r·ªóng sau {max_retries} l·∫ßn th·ª≠ t·∫°i conversation_id={conversation_id}",
                "AI Handler - Final Skip"
            )
            return

        # Ki·ªÉm tra xem c√≥ AI message n√†o ƒëang pending kh√¥ng (tr√°nh duplicate reply)
        recent_ai_messages = frappe.get_all(
            "ChatMessage",
            filters={
                "parent": conversation_id,
                "is_user": 0,
                "creation": [">=", frappe.utils.add_to_date(frappe.utils.now(), minutes=-2)]
            },
            limit_page_length=1
        )
        
        if recent_ai_messages:
            frappe.logger().info(f"[AI SKIPPED] Recent AI message found for conversation {conversation_id}, skipping duplicate reply")
            return

        ai_reply = call_openai(context)
        chat_message = create_message(conversation_id, ai_reply, is_user=False)
        frappe.db.commit()

        frappe.publish_realtime(
            event='raven:new_ai_message',
            message={
                'conversation_id': conversation_id,
                'message': ai_reply,
                'message_id': chat_message.name
            },
            after_commit=True
        )

        frappe.logger().info(f"[AI SUCCESS] AI reply completed for conversation {conversation_id}")

    except Exception as e:
        frappe.log_error(
            f"Error handling AI reply:\n{str(e)}\n{traceback.format_exc()}",
            "AI Handler Error"
        )
    finally:
        # Lu√¥n clear lock khi ho√†n th√†nh
        frappe.cache().delete(lock_key)



@frappe.whitelist()
def rename_conversation(conversation_id, title):
    max_retries = 3
    retry_delay = 0.5  # 500ms

    for attempt in range(max_retries):
        try:
            if not frappe.db.exists("ChatConversation", conversation_id):
                frappe.throw(_("Cu·ªôc tr√≤ chuy·ªán kh√¥ng t·ªìn t·∫°i"))

            # L·∫•y document m·ªõi nh·∫•t t·ª´ database
            conversation = frappe.get_doc("ChatConversation", conversation_id)
            old_title = conversation.title
            conversation.title = title

            # S·ª≠ d·ª•ng ignore_version=True ƒë·ªÉ b·ªè qua timestamp check
            conversation.save(ignore_permissions=True, ignore_version=True)
            frappe.db.commit()

            frappe.publish_realtime(
                event='raven:update_conversation_title',
                message={
                    'conversation_id': conversation_id,
                    'old_title': old_title,
                    'new_title': title,
                    'creation': conversation.creation
                },
                after_commit=True,
                doctype="ChatConversation"
            )

            return conversation

        except frappe.exceptions.TimestampMismatchError as e:
            if attempt < max_retries - 1:
                frappe.log_error(
                    f"[RENAME RETRY] Attempt {attempt + 1}/{max_retries} - TimestampMismatchError, ƒëang retry...",
                    "Rename Conversation - Retry"
                )
                time.sleep(retry_delay)
                retry_delay *= 2  # Exponential backoff
                continue
            else:
                # N·∫øu v·∫´n l·ªói sau max_retries, th·ª≠ c√°ch kh√°c
                try:
                    # S·ª≠ d·ª•ng frappe.db.set_value ƒë·ªÉ update tr·ª±c ti·∫øp
                    frappe.db.set_value("ChatConversation", conversation_id, "title", title)
                    frappe.db.commit()

                    # L·∫•y l·∫°i conversation sau khi update
                    conversation = frappe.get_doc("ChatConversation", conversation_id)

                    frappe.publish_realtime(
                        event='raven:update_conversation_title',
                        message={
                            'conversation_id': conversation_id,
                            'old_title': old_title if 'old_title' in locals() else '',
                            'new_title': title,
                            'creation': conversation.creation
                        },
                        after_commit=True,
                        doctype="ChatConversation"
                    )

                    return conversation

                except Exception as fallback_error:
                    frappe.log_error(
                        f"[RENAME FALLBACK ERROR] {str(fallback_error)}\n{traceback.format_exc()}",
                        "Rename Conversation - Fallback Failed"
                    )
                    frappe.throw(_("Kh√¥ng th·ªÉ ƒë·ªïi t√™n cu·ªôc tr√≤ chuy·ªán sau nhi·ªÅu l·∫ßn th·ª≠"))

        except Exception as e:
            frappe.log_error(
                f"[RENAME ERROR] Attempt {attempt + 1}: {str(e)}\n{traceback.format_exc()}",
                "Rename Conversation - General Error"
            )
            if attempt == max_retries - 1:
                frappe.throw(_("C√≥ l·ªói x·∫£y ra khi ƒë·ªïi t√™n cu·ªôc tr√≤ chuy·ªán"))

    frappe.throw(_("Kh√¥ng th·ªÉ ƒë·ªïi t√™n cu·ªôc tr√≤ chuy·ªán sau nhi·ªÅu l·∫ßn th·ª≠"))